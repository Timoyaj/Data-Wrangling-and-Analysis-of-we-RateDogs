# Data-Wrangling-and-Analysis-of-we-RateDogs
Project Wrangle and Analyze data was the second project carried out during the ALX -Udacity Nanodegree in Data Analytics. Real-world data rarely come clean. Using Python and its libraries, we were asked to gathered data from various sources and in a variety of formats, assess its quality and tidiness, then clean for exploratory analysis. 

We wrangled the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. We gathered three different pieces of data from various sources using different methods.The twitter_archive_enhanced.csv was given in our Udacity work space which we downloaded manually. The file image_predictions.tsv was hosted on Udacity's servers which was downloaded programmatically using the Requests library from the URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv. And finally, from the Twitter API we gather each tweet's retweet count and favorite ("like") count using the tweet IDs in the WeRateDogs Twitter archive data using the Python tweepy library.

After gathering all three pieces of data. we assessed the data using Visual assessment:i.e. Each piece of gathered data was displayed in the Jupyter Notebook for visual assessment purposes. This was achieved by setting the display limits to the length and width of the dataframe. And  Programmatic assessment:using pandas' functions and/or methods to assess the data. Quality and Tidyness issues were identified and appropriately cleaned.

The gathered, assessed, and cleaned twitter archive data sets were merged into a master dataset and saved to a CSV file with the name "twitter_archive_master.csv" ready for exploratory analysis. 
